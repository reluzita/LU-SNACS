{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONDMAT\n",
      "# nodes: 23133\n",
      "# edges: 93497\n",
      "avg degree: 8.083430596982666\n",
      "density: 0.0003494479766981958\n"
     ]
    }
   ],
   "source": [
    "edges_dict = {}\n",
    "with open('data/ca-CondMat.txt', \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[4:]:\n",
    "        data = line.strip().split(\"\\t\")\n",
    "        if (int(data[0]), int(data[1])) in edges_dict:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] += 1\n",
    "        elif (int(data[1]), int(data[0])) in edges_dict:\n",
    "            edges_dict[(int(data[1]), int(data[0]))] += 1\n",
    "        else:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] = 1\n",
    "        \n",
    "edges = [(k[0], k[1], v) for k, v in edges_dict.items()]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "print(\"CONDMAT\")\n",
    "print(\"# nodes:\", G.number_of_nodes())\n",
    "print(\"# edges:\", G.number_of_edges())\n",
    "print(\"avg degree:\", np.mean([x[1] for x in list(G.degree())]))\n",
    "print(\"density:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reality Mining\n",
      "# nodes: 96\n",
      "# edges: 2539\n",
      "avg degree: 52.895833333333336\n",
      "density: 0.5567982456140351\n"
     ]
    }
   ],
   "source": [
    "edges_dict = {}\n",
    "with open('data/datasets/mit/out.mit', \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        data = line.strip().split(\" \")\n",
    "        data = [data[0]] + data[1].split(\"\\t\")\n",
    "        if (int(data[0]), int(data[1])) in edges_dict:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] += 1\n",
    "        elif (int(data[1]), int(data[0])) in edges_dict:\n",
    "            edges_dict[(int(data[1]), int(data[0]))] += 1\n",
    "        else:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] = 1\n",
    "        \n",
    "edges = [(k[0], k[1], v) for k, v in edges_dict.items()]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "print(\"Reality Mining\")\n",
    "print(\"# nodes:\", G.number_of_nodes())\n",
    "print(\"# edges:\", G.number_of_edges())\n",
    "print(\"avg degree:\", np.mean([x[1] for x in list(G.degree())]))\n",
    "print(\"density:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology\n",
      "# nodes: 34761\n",
      "# edges: 107720\n",
      "avg degree: 6.197750352406432\n",
      "density: 0.0001783012184236603\n"
     ]
    }
   ],
   "source": [
    "edges_dict = {}\n",
    "with open('data/datasets/topology/out.topology', \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        data = line.strip().split(\" \")\n",
    "        if (int(data[0]), int(data[1])) in edges_dict:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] += 1\n",
    "        elif (int(data[1]), int(data[0])) in edges_dict:\n",
    "            edges_dict[(int(data[1]), int(data[0]))] += 1\n",
    "        else:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] = 1\n",
    "        \n",
    "edges = [(k[0], k[1], v) for k, v in edges_dict.items()]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "print(\"Topology\")\n",
    "print(\"# nodes:\", G.number_of_nodes())\n",
    "print(\"# edges:\", G.number_of_edges())\n",
    "print(\"avg degree:\", np.mean([x[1] for x in list(G.degree())]))\n",
    "print(\"density:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter\n",
      "# nodes: 11000\n",
      "# edges: 18173\n",
      "avg degree: 3.304181818181818\n",
      "density: 0.00030040747505971616\n"
     ]
    }
   ],
   "source": [
    "edges_dict = {}\n",
    "users = set()\n",
    "tags = set()\n",
    "with open('data/datasets/munmun_twitterex_ut/out.munmun_twitterex_ut', \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        data = line.strip().split(\" \")\n",
    "        user = 'user' + data[0]\n",
    "        tag = 'tag' + data[1]\n",
    "        if len(users) < 1000 or user in users:\n",
    "            if len(tags) < 10000 or tag in tags:\n",
    "                users.add(user)\n",
    "                tags.add(tag)\n",
    "                \n",
    "                if (user, tag) not in edges_dict:\n",
    "                    edges_dict[(user, tag)] = 1\n",
    "                else:\n",
    "                    edges_dict[(user, tag)] += 1\n",
    " \n",
    "edges = [(k[0], k[1], v) for k, v in edges_dict.items()]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "print(\"Twitter\")\n",
    "print(\"# nodes:\", G.number_of_nodes())\n",
    "print(\"# edges:\", G.number_of_edges())\n",
    "print(\"avg degree:\", np.mean([x[1] for x in list(G.degree())]))\n",
    "print(\"density:\", nx.density(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosper Loans\n",
      "# nodes: 89269\n",
      "# edges: 3330022\n",
      "avg degree: 74.60645912914897\n",
      "density: 0.00041787907833237543\n"
     ]
    }
   ],
   "source": [
    "edges_dict = {}\n",
    "with open('data/datasets/prosper-loans/out.prosper-loans', \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        data = line.strip().split(\" \")\n",
    "        data = [data[0]] + data[1].split(\"\\t\")\n",
    "        if (int(data[0]), int(data[1])) in edges_dict:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] += 1\n",
    "        elif (int(data[1]), int(data[0])) in edges_dict:\n",
    "            edges_dict[(int(data[1]), int(data[0]))] += 1\n",
    "        else:\n",
    "            edges_dict[(int(data[0]), int(data[1]))] = 1\n",
    "        \n",
    "edges = [(k[0], k[1], v) for k, v in edges_dict.items()]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "print(\"Prosper Loans\")\n",
    "print(\"# nodes:\", G.number_of_nodes())\n",
    "print(\"# edges:\", G.number_of_edges())\n",
    "print(\"avg degree:\", np.mean([x[1] for x in list(G.degree())]))\n",
    "print(\"density:\", nx.density(G))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f27b976aa897af32c09d5b2017e6eaeae9fce6dda3a991c257df1513f3b41573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
